from bayes_opt import BayesianOptimization
from sklearn.model_selection import ParameterGrid

from src.search.simulation import simulate
from src.search.strategy.random_walker_1 import RandomWalker1StrategyParams
from src.torus_creation.random_grid import RandomStrategyParams


def simit(random_probability, random_probability_of_adding_edge, length_of_memory, num_random_walker):
    results = []
    for i in range(20):
        res = simulate(
            graph_strategy="random",
            graph_stratey_params=RandomStrategyParams(),
            grid_width=40,
            grid_height=40,
            num_distinct_information=100,
            random_walker_strategy="random_walker_1",
            random_walker_strategy_params=RandomWalker1StrategyParams(
                random_probability=random_probability,
                random_probability_of_adding_edge=random_probability_of_adding_edge,
                length_of_memory=length_of_memory,
            ),
            num_random_walker=num_random_walker,
            searched_information=50,
            max_steps=3000,
        )

        results.append(res)

    # return average num_steps
    return sum([r["num_steps"] for r in results]) / len(results)

# param_grid = {
#     'random_probability': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99],
#     'random_probability_of_adding_edge': [0.005, 0.010, 0.015, 0.020, 0.1, 0.15, 0.2],
#     'length_of_memory': [5, 10, 15, 50, 100, 150, 200, 300, 400, 500, 600, 700, 800],
#     'num_random_walker': [10],
# }
#
# for params in ParameterGrid(param_grid):
#     avg_steps = simit(params['random_probability'], params['random_probability_of_adding_edge'], params['length_of_memory'], params['num_random_walker'])
#
#     print(f"{params['random_probability']}, {params['random_probability_of_adding_edge']}, {params['length_of_memory']}, {params['num_random_walker']}: {avg_steps}")
#
#     # also print to file (append)
#     with open("results.txt", "a") as f:
#         f.write(f"{params['random_probability']}, {params['random_probability_of_adding_edge']}, {params['length_of_memory']}, {params['num_random_walker']}: {avg_steps}\n")

# use bayesopt

import loguru
loguru.logger.remove()
loguru.logger.add("bayesopt.log", level="ERROR")

def black_box_function(random_probability, random_probability_of_adding_edge, length_of_memory):
    return 3000 - simit(random_probability, random_probability_of_adding_edge, int(length_of_memory), 10)

pbounds = {
    'random_probability': (0.01, 0.99),
    'random_probability_of_adding_edge': (0.005, 0.3),
    'length_of_memory': (5, 800)
}

optimizer = BayesianOptimization(
    f=black_box_function,
    pbounds=pbounds,
    random_state=1,
)

optimizer.maximize(
    init_points=50,
    n_iter=100,
)

print(optimizer.max)

# |   iter    |  target   | length... | random... | random... |
# -------------------------------------------------------------
# | 1         | 1.841e+03 | 336.5     | 0.7159    | 0.005034  |
# | 2         | 0.0       | 245.4     | 0.1538    | 0.03224   |
# | 3         | 198.4     | 153.1     | 0.3486    | 0.122     |
# | 4         | 211.5     | 433.4     | 0.4208    | 0.2071    |
# | 5         | 1.796e+03 | 167.5     | 0.8706    | 0.01308   |
# | 6         | 738.2     | 538.0     | 0.419     | 0.1698    |
# | 7         | 5.2       | 116.6     | 0.2041    | 0.2412    |
# | 8         | 255.6     | 774.8     | 0.3172    | 0.2092    |
# | 9         | 1.817e+03 | 701.7     | 0.8867    | 0.03009   |
# | 10        | 0.0       | 36.05     | 0.1764    | 0.2641    |
# | 11        | 400.3     | 83.19     | 0.4227    | 0.2876    |
# | 12        | 1.742e+03 | 428.9     | 0.688     | 0.09808   |
# | 13        | 2.08e+03  | 550.8     | 0.8279    | 0.0104    |
# | 14        | 1.566e+03 | 601.4     | 0.9791    | 0.2257    |
# | 15        | 1.773e+03 | 228.0     | 0.7835    | 0.03545   |
# | 16        | 1.827e+03 | 361.1     | 0.9004    | 0.09162   |
# | 17        | 0.0       | 233.8     | 0.1374    | 0.01071   |
# | 18        | 77.7      | 544.7     | 0.2174    | 0.08334   |
# | 19        | 0.0       | 395.8     | 0.0623    | 0.1744    |
# | 20        | 652.2     | 121.6     | 0.5875    | 0.2114    |
# | 21        | 319.8     | 86.36     | 0.4158    | 0.2098    |
# | 22        | 0.0       | 334.3     | 0.05895   | 0.1631    |
# | 23        | 984.8     | 532.7     | 0.5146    | 0.2837    |
# | 24        | 1.67e+03  | 471.3     | 0.8953    | 0.04556   |
# | 25        | 1.713e+03 | 115.7     | 0.8012    | 0.1223    |
# | 26        | 1.968e+03 | 136.5     | 0.919     | 0.1076    |
# | 27        | 1.784e+03 | 601.9     | 0.7215    | 0.2656    |
# | 28        | 1.926e+03 | 500.8     | 0.7459    | 0.1079    |
# | 29        | 1.947e+03 | 219.6     | 0.888     | 0.1313    |
# | 30        | 1.768e+03 | 772.0     | 0.6602    | 0.1884    |
# | 31        | 1.957e+03 | 96.22     | 0.9405    | 0.1377    |
# | 32        | 523.6     | 464.8     | 0.41      | 0.07492   |
# | 33        | 1.348e+03 | 723.2     | 0.5722    | 0.005847  |
# | 34        | 252.7     | 495.6     | 0.3301    | 0.1605    |
# | 35        | 175.9     | 709.3     | 0.3601    | 0.273     |
# | 36        | 0.0       | 500.6     | 0.0255    | 0.2792    |
# | 37        | 1.774e+03 | 554.3     | 0.9874    | 0.05584   |
# | 38        | 1.896e+03 | 114.0     | 0.9239    | 0.2106    |
# | 39        | 1.796e+03 | 57.47     | 0.7504    | 0.2274    |
# | 40        | 1.655e+03 | 738.8     | 0.7073    | 0.04166   |
# | 41        | 0.0       | 20.8      | 0.03569   | 0.01335   |
# | 42        | 1.867e+03 | 200.7     | 0.8528    | 0.164     |
# | 43        | 1.805e+03 | 444.5     | 0.8352    | 0.04163   |
# | 44        | 1.193e+03 | 227.0     | 0.584     | 0.291     |
# | 45        | 0.0       | 451.0     | 0.02827   | 0.2412    |
# | 46        | 1.73e+03  | 190.2     | 0.801     | 0.1194    |
# | 47        | 1.546e+03 | 691.5     | 0.7422    | 0.1691    |
# | 48        | 0.0       | 113.5     | 0.06872   | 0.0408    |
# | 49        | 0.0       | 40.42     | 0.1153    | 0.07158   |
# | 50        | 1.444e+03 | 571.8     | 0.5585    | 0.008704  |
# | 51        | 1.868e+03 | 550.6     | 0.9234    | 0.1849    |
# | 52        | 598.1     | 550.4     | 0.405     | 0.008428  |
# | 53        | 1.67e+03  | 550.9     | 0.7413    | 0.2422    |
# | 54        | 0.0       | 185.9     | 0.1625    | 0.2845    |
# | 55        | 1.792e+03 | 582.4     | 0.724     | 0.06243   |
# | 56        | 1.824e+03 | 136.8     | 0.7562    | 0.0885    |
# | 57        | 1.782e+03 | 764.6     | 0.6608    | 0.1439    |
# | 58        | 1.961e+03 | 393.5     | 0.8344    | 0.2938    |
# | 59        | 1.792e+03 | 114.5     | 0.9462    | 0.1668    |
# | 60        | 308.8     | 136.2     | 0.3626    | 0.05226   |
# | 61        | 1.253e+03 | 543.3     | 0.547     | 0.118     |
# | 62        | 0.0       | 116.9     | 0.1466    | 0.09847   |
# | 63        | 1.846e+03 | 222.8     | 0.7591    | 0.02473   |
# | 64        | 1.77e+03  | 501.3     | 0.9418    | 0.2127    |
# | 65        | 0.0       | 480.6     | 0.1204    | 0.03945   |
# | 66        | 1.148e+03 | 492.8     | 0.5562    | 0.1978    |
# | 67        | 0.0       | 18.37     | 0.2632    | 0.2412    |
# | 68        | 1.72e+03  | 115.7     | 0.7939    | 0.1076    |
# | 69        | 1.849e+03 | 392.9     | 0.9367    | 0.223     |
# | 70        | 0.0       | 393.2     | 0.1652    | 0.1976    |
# | 71        | 987.8     | 219.2     | 0.4663    | 0.1935    |
# | 72        | 0.0       | 187.9     | 0.07349   | 0.2126    |
# | 73        | 1.028e+03 | 95.76     | 0.6156    | 0.1827    |
# | 74        | 1.693e+03 | 220.1     | 0.956     | 0.105     |
# | 75        | 269.4     | 672.2     | 0.4201    | 0.09235   |
# | 76        | 1.831e+03 | 96.71     | 0.7636    | 0.2013    |
# | 77        | 0.0       | 200.8     | 0.2196    | 0.2617    |
# | 78        | 1.806e+03 | 222.3     | 0.9581    | 0.1583    |
# | 79        | 494.6     | 222.3     | 0.4055    | 0.2099    |
# | 80        | 1.964e+03 | 393.9     | 0.9494    | 0.07797   |
# | 81        | 0.0       | 336.7     | 0.1523    | 0.1761    |
# | 82        | 0.0       | 87.05     | 0.06601   | 0.114     |
# | 83        | 1.914e+03 | 336.2     | 0.9862    | 0.2648    |
# | 84        | 1.839e+03 | 223.3     | 0.9626    | 0.2223    |
# | 85        | 1.662e+03 | 360.6     | 0.5816    | 0.02711   |
# | 86        | 0.0       | 361.2     | 0.1672    | 0.2159    |
# | 87        | 710.2     | 223.5     | 0.4662    | 0.05788   |
# | 88        | 1.783e+03 | 335.8     | 0.7081    | 0.1328    |
# | 89        | 1.657e+03 | 200.3     | 0.8795    | 0.04215   |
# | 90        | 1.908e+03 | 701.2     | 0.7422    | 0.251     |
# | 91        | 31.45     | 605.0     | 0.2416    | 0.2632    |
# | 92        | 20.8      | 701.3     | 0.193     | 0.1103    |
# | 93        | 1.601e+03 | 649.6     | 0.7423    | 0.2674    |
# | 94        | 1.898e+03 | 444.5     | 0.8128    | 0.03983   |
# | 95        | 10.3      | 444.5     | 0.2546    | 0.1367    |
# | 96        | 1.923e+03 | 200.7     | 0.8756    | 0.1709    |
# | 97        | 318.0     | 96.42     | 0.4484    | 0.2238    |
# | 98        | 1.69e+03  | 336.1     | 0.6703    | 0.0137    |
# | 99        | 1.724e+03 | 701.4     | 0.9719    | 0.01213   |
# | 100       | 1.968e+03 | 700.9     | 0.99      | 0.3       |
# | 101       | 1.8e+03   | 97.15     | 0.936     | 0.02427   |
# | 102       | 1.539e+03 | 38.55     | 0.6545    | 0.2974    |
# | 103       | 1.193e+03 | 219.8     | 0.5916    | 0.1461    |
# | 104       | 1.67e+03  | 91.37     | 0.8091    | 0.2925    |
# | 105       | 0.0       | 698.0     | 0.185     | 0.1285    |
# | 106       | 1.15e+03  | 394.1     | 0.6674    | 0.2384    |
# | 107       | 1.312e+03 | 501.2     | 0.5729    | 0.005     |
# | 108       | 1.722e+03 | 582.4     | 0.6784    | 0.08242   |
# | 109       | 1.96e+03  | 700.6     | 0.7672    | 0.06737   |
# | 110       | 1.794e+03 | 336.6     | 0.9889    | 0.2127    |
# | 111       | 1.852e+03 | 393.2     | 0.8933    | 0.03242   |
# | 112       | 1.097e+03 | 73.57     | 0.5463    | 0.04778   |
# | 113       | 371.2     | 601.5     | 0.3502    | 0.1351    |
# | 114       | 1.92e+03  | 700.3     | 0.8653    | 0.2728    |
# | 115       | 294.8     | 700.2     | 0.4327    | 0.2307    |
# | 116       | 1.826e+03 | 360.7     | 0.9644    | 0.229     |
# | 117       | 1.737e+03 | 96.64     | 0.9803    | 0.03976   |
# | 118       | 1.77e+03  | 602.4     | 0.8005    | 0.2372    |
# | 119       | 2.004e+03 | 407.0     | 0.9801    | 0.1237    |
# | 120       | 1.407e+03 | 407.1     | 0.5505    | 0.01668   |
# | 121       | 2.008e+03 | 369.4     | 0.9599    | 0.1729    |
# | 122       | 1.877e+03 | 369.8     | 0.9406    | 0.1588    |
# | 123       | 1.866e+03 | 111.9     | 0.9299    | 0.007794  |
# | 124       | 784.0     | 369.5     | 0.4954    | 0.2166    |
# | 125       | 0.0       | 145.5     | 0.215     | 0.1615    |
# | 126       | 0.0       | 661.2     | 0.1275    | 0.1697    |
# | 127       | 1.806e+03 | 701.2     | 0.71      | 0.2278    |
# | 128       | 1.908e+03 | 222.8     | 0.9493    | 0.2993    |
# | 129       | 1.715e+03 | 406.7     | 0.7346    | 0.2641    |
# | 130       | 1.675e+03 | 665.7     | 0.8335    | 0.1636    |
# | 131       | 1.793e+03 | 407.5     | 0.99      | 0.3       |
# | 132       | 0.0       | 635.1     | 0.1481    | 0.2387    |
# | 133       | 1.661e+03 | 368.8     | 0.9617    | 0.2474    |
# | 134       | 0.0       | 315.1     | 0.04458   | 0.05068   |
# | 135       | 333.9     | 111.9     | 0.3699    | 0.1703    |
# | 136       | 1.883e+03 | 581.8     | 0.854     | 0.01562   |
# | 137       | 216.1     | 581.6     | 0.2823    | 0.1157    |
# | 138       | 654.7     | 114.9     | 0.5243    | 0.1687    |
# | 139       | 1.443e+03 | 500.3     | 0.9458    | 0.1381    |
# | 140       | 715.8     | 57.09     | 0.4023    | 0.03476   |
# | 141       | 1.745e+03 | 57.88     | 0.8598    | 0.00918   |
# | 142       | 193.9     | 57.9      | 0.2872    | 0.2485    |
# | 143       | 1.57e+03  | 702.2     | 0.99      | 0.3       |
# | 144       | 1.899e+03 | 360.2     | 0.99      | 0.005     |
# | 145       | 1.42e+03  | 360.1     | 0.6056    | 0.209     |
# | 146       | 728.3     | 97.29     | 0.5635    | 0.2675    |
# | 147       | 339.3     | 167.6     | 0.3355    | 0.01976   |
# | 148       | 1.806e+03 | 551.1     | 0.99      | 0.005     |
# | 149       | 1.127e+03 | 764.0     | 0.553     | 0.1487    |
# | 150       | 0.0       | 239.5     | 0.01834   | 0.05095   |
# =============================================================
# {'target': 2080.2, 'params': {'length_of_memory': 550.768237506859, 'random_probability': 0.8279331584594255, 'random_probability_of_adding_edge': 0.010395041816536582}}
